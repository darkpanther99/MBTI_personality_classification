{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-12-16T20:20:13.200546Z","iopub.status.busy":"2022-12-16T20:20:13.199619Z","iopub.status.idle":"2022-12-16T20:20:28.505954Z","shell.execute_reply":"2022-12-16T20:20:28.504788Z","shell.execute_reply.started":"2022-12-16T20:20:13.200508Z"},"trusted":true},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","from torch import nn\n","import torch\n","from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n","from torch.utils.data import Dataset, DataLoader, random_split\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from torchtext.vocab import GloVe,vocab\n","from transformers import (set_seed,\n","                          AutoTokenizer,\n","                          AutoModelForQuestionAnswering,\n","                          TrainingArguments,\n","                          Trainer,\n","                          AdamW,\n","                          get_linear_schedule_with_warmup,\n","                          RobertaTokenizer,\n","                          RobertaForSequenceClassification,\n","                          RobertaModel,\n","                          RobertaConfig,\n","                          RobertaPreTrainedModel)\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score, precision_score, recall_score\n","from typing import Optional, Tuple, Union\n","from transformers.modeling_outputs import SequenceClassifierOutputWithPast"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-12-16T20:20:28.520598Z","iopub.status.busy":"2022-12-16T20:20:28.519556Z","iopub.status.idle":"2022-12-16T20:20:28.536491Z","shell.execute_reply":"2022-12-16T20:20:28.535598Z","shell.execute_reply.started":"2022-12-16T20:20:28.520559Z"},"trusted":true},"outputs":[],"source":["def convert_personality_type_to_binary(mbti_type):\n","    mapper = {\n","        'I':0,\n","        'E':1,\n","        'N':0,\n","        'S':1,\n","        'T':0,\n","        'F':1,\n","        'J':0,\n","        'P':1,\n","    }\n","\n","    return [mapper[i] for i in mbti_type]\n","\n","def convert_personality_type_to_int(mbti_type):\n","    types = [\n","                'INTJ', 'INTP', 'ISFJ', 'ISFP',\n","                'ISTJ', 'ISTP', 'ENFJ', 'ENFP',\n","                'ENTJ', 'ENTP','ESFJ', 'ESFP',\n","                'ESTJ', 'ESTP', 'INFJ', 'INFP'\n","            ]\n","    ints = [i for i in range(len(types))]\n","    mapper = dict(zip(types, ints))\n","\n","    return mapper[mbti_type]\n","\n","def convert_binary_to_personality_type(binary_mbti_type):\n","    mbti_arrays = [['I', 'E'], ['N', 'S'], ['T', 'F'], ['J', 'P']]\n","    mbti_string = ''\n","    for idx, mbti_type in enumerate(binary_mbti_type):\n","        mbti_string += mbti_arrays[idx][int(mbti_type)]\n","    return mbti_string"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-12-16T20:20:28.540749Z","iopub.status.busy":"2022-12-16T20:20:28.540471Z","iopub.status.idle":"2022-12-16T20:20:28.774378Z","shell.execute_reply":"2022-12-16T20:20:28.773425Z","shell.execute_reply.started":"2022-12-16T20:20:28.540724Z"},"trusted":true},"outputs":[],"source":["class MBTIDataset(Dataset):\n","    def __init__(self, data_path, vectorizing_method = None, binary_outputs = False, max_seq_len=500):\n","        \"\"\"\n","        Vectorizing methods:\n","        None - returns raw text\n","        basic - basic builtin pytorch vectorizer\n","        TfIdf - tf-idf vectorizer\n","        GloVe - Global Vectors pretrained embedding\n","        \"\"\"\n","        self.df = pd.read_csv(data_path)\n","        self.vectorizing_method = vectorizing_method\n","        self.max_seq_len = max_seq_len\n","        self.split_dataframe(self.max_seq_len)\n","\n","        if vectorizing_method:\n","            if vectorizing_method.lower == 'basic':\n","                self.tokenizer = get_tokenizer('basic_english')\n","                self.vocab = build_vocab_from_iterator(self.yield_tokens_from_dataframe(), specials=['<unk>'])\n","                self.vocab.set_default_index(self.vocab[\"<unk>\"])\n","\n","            if vectorizing_method.lower == 'tfidf' or vectorizing_method.lower == 'tf-idf':\n","                self.tokenizer = TfidfVectorizer(stop_words= 'english')\n","                self.vocab = self.tokenizer.fit_transform(self.df['posts']) # Sparse matrix representation - could use different field names\n","            if vectorizing_method.lower == 'glove':\n","                unk_index = 0\n","                self.global_vectors = GloVe(name='6B', dim=50)\n","                self.vocab=vocab(self.global_vectors.stoi)\n","                self.vocab.insert_token(\"<unk>\",unk_index)\n","                self.vocab.set_default_index(unk_index)\n","\n","                self.pretrained_embeddings = self.global_vectors.vectors\n","                self.pretrained_embeddings = torch.cat((torch.zeros(1,self.pretrained_embeddings.shape[1]),self.pretrained_embeddings))\n","\n","\n","        self.binary_outputs = binary_outputs\n","        if binary_outputs:\n","            self.df['type'] = self.df['type'].apply(convert_personality_type_to_binary)\n","        else:\n","            self.df['type'] = self.df['type'].apply(convert_personality_type_to_int)\n","\n","    def yield_tokens_from_dataframe(self):\n","        for post in self.df['posts']:\n","            yield self.tokenizer(post)\n","\n","    def split_dataframe(self, new_seq_len):\n","        new_df = pd.DataFrame(columns=self.df.columns)\n","        new_posts = []\n","        new_types = []\n","        for idx, row in self.df.iterrows():\n","            split_posts = row['posts'].split(' ')\n","            i = 0\n","            while i < len(split_posts):\n","                new_posts.append((' ').join(split_posts[i:i+new_seq_len]))\n","                new_types.append(row['type'])\n","                i += new_seq_len\n","\n","        new_df['posts'] = new_posts\n","        new_df['type'] = new_types\n","        self.df = new_df\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        if idx >= len(self): raise IndexError\n","\n","        if not self.vectorizing_method :\n","            return self.df['posts'][idx], self.df['type'][idx]\n","\n","        input_text = self.vocab(self.df['posts'][idx].split(' '))\n","        if len(input_text) < self.max_seq_len:\n","            input_text.extend([0] * (self.max_seq_len-len(input_text)))\n","        label = self.df['type'][idx]\n","\n","        return input_text[0:self.max_seq_len], label"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-12-16T20:20:28.776878Z","iopub.status.busy":"2022-12-16T20:20:28.776519Z","iopub.status.idle":"2022-12-16T20:20:28.791325Z","shell.execute_reply":"2022-12-16T20:20:28.790225Z","shell.execute_reply.started":"2022-12-16T20:20:28.776815Z"},"trusted":true},"outputs":[],"source":["class RoBERTaClassificationCollator(object):\n","\n","    def __init__(self, use_tokenizer, max_sequence_len=None):\n","\n","        self.use_tokenizer = use_tokenizer\n","        self.max_sequence_len = use_tokenizer.model_max_length if max_sequence_len is None else max_sequence_len\n","\n","    def __call__(self, sequences):\n","\n","        texts = [sequence[0] for sequence in sequences]\n","        labels = [sequence[1] for sequence in sequences]\n","        inputs = self.use_tokenizer(text=texts, return_tensors=\"pt\", padding=True, truncation=True,  max_length=self.max_sequence_len)\n","        inputs.update({'labels':torch.tensor(labels)})\n","\n","        return inputs"]},{"cell_type":"markdown","metadata":{},"source":["# Integer outputs"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-12-16T20:20:35.783489Z","iopub.status.busy":"2022-12-16T20:20:35.783125Z","iopub.status.idle":"2022-12-16T20:21:00.251048Z","shell.execute_reply":"2022-12-16T20:21:00.249922Z","shell.execute_reply.started":"2022-12-16T20:20:35.783457Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"888eb8b03549476fb25f6325464c5a6e","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ce3ee317b9e14bb19a7777b5cb992fc1","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"585b6dd957ba425791d738f0d1e1a492","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["max_seq_len = 500\n","tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n","tokenizer.padding_side = \"right\"\n","roberta_classificaiton_collator = RoBERTaClassificationCollator(use_tokenizer=tokenizer, max_sequence_len=max_seq_len)\n","\n","ds = MBTIDataset('../input/mbti-personality-types-500-dataset/MBTI 500.csv', vectorizing_method = None, binary_outputs=False, max_seq_len = max_seq_len)\n","train_set_size = int(len(ds)*0.7)\n","val_set_size = int(len(ds)*0.2)\n","test_set_size = len(ds) - train_set_size - val_set_size\n","train_ds, val_ds, test_ds = random_split(ds, [train_set_size, val_set_size, test_set_size])\n","\n","train_dataloader = DataLoader(train_ds, batch_size=8, shuffle=True, collate_fn=roberta_classificaiton_collator)\n","val_dataloader = DataLoader(val_ds, batch_size=8, shuffle=True, collate_fn=roberta_classificaiton_collator)\n","test_dataloader = DataLoader(test_ds, batch_size=8, shuffle=True, collate_fn=roberta_classificaiton_collator)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-12-16T20:21:00.253640Z","iopub.status.busy":"2022-12-16T20:21:00.253243Z","iopub.status.idle":"2022-12-16T20:21:14.248336Z","shell.execute_reply":"2022-12-16T20:21:14.247398Z","shell.execute_reply.started":"2022-12-16T20:21:00.253605Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5d13dace6e2f4549990a0623baee07c3","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/478M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = RobertaForSequenceClassification.from_pretrained(\n","    \"roberta-base\",\n","    num_labels = 16,\n","    output_attentions = False,\n","    output_hidden_states = False,\n","    ignore_mismatched_sizes=True #https://github.com/huggingface/transformers/issues/14218\n",")"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-12-16T20:21:14.250446Z","iopub.status.busy":"2022-12-16T20:21:14.249691Z","iopub.status.idle":"2022-12-16T20:21:22.304320Z","shell.execute_reply":"2022-12-16T20:21:22.303298Z","shell.execute_reply.started":"2022-12-16T20:21:14.250406Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","model.to(device)\n","\n","optimizer = torch.optim.AdamW(model.parameters(),\n","                  lr = 2e-5,eps = 1e-8)\n","\n","epochs = 5\n","total_steps = len(train_dataloader) * epochs\n","\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-16T20:23:17.922143Z","iopub.status.busy":"2022-12-16T20:23:17.921759Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 10400/10400 [2:23:38<00:00,  1.21it/s] \n"]},{"name":"stdout","output_type":"stream","text":["Train loss: 1.081580814633411\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2972/2972 [14:48<00:00,  3.34it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation loss: 0.8352050414991415\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 10400/10400 [2:23:52<00:00,  1.20it/s] \n"]},{"name":"stdout","output_type":"stream","text":["Train loss: 0.7723910580335471\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2972/2972 [14:25<00:00,  3.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation loss: 0.7967360299666604\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 10400/10400 [2:23:38<00:00,  1.21it/s] \n"]},{"name":"stdout","output_type":"stream","text":["Train loss: 0.6693442779536753\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2972/2972 [14:26<00:00,  3.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation loss: 0.7578748355816717\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 10400/10400 [2:23:05<00:00,  1.21it/s] \n"]},{"name":"stdout","output_type":"stream","text":["Train loss: 0.5918162566189914\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2972/2972 [14:24<00:00,  3.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation loss: 0.8027114576212298\n"]},{"name":"stderr","output_type":"stream","text":[" 59%|█████▉    | 6122/10400 [1:24:16<58:48,  1.21it/s]  "]}],"source":["for epoch in range(epochs):\n","    model.train()\n","    predictions_labels = []\n","    true_labels = []\n","    total_loss = 0\n","    \n","    for batch in tqdm(train_dataloader, total=len(train_dataloader), position=0, leave=True):\n","\n","        true_labels += batch['labels'].numpy().flatten().tolist()\n","        batch = {k:v.type(torch.long).to(device) for k,v in batch.items()}\n","        model.zero_grad()\n","        outputs = model(**batch)\n","        loss, logits = outputs[:2]\n","        total_loss += loss.item()\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","        scheduler.step()\n","        logits = logits.detach().cpu().numpy()\n","        predictions_labels += logits.argmax(axis=-1).flatten().tolist()\n","    \n","\n","    avg_epoch_loss = total_loss / len(train_dataloader)\n","    print('Train loss:', avg_epoch_loss)\n","    \n","    predictions_labels = []\n","    true_labels = []\n","    total_loss = 0\n","    model.eval()\n","\n","    for batch in tqdm(val_dataloader, total=len(val_dataloader), position=0, leave=True):\n","\n","        true_labels += batch['labels'].numpy().flatten().tolist()\n","        batch = {k:v.type(torch.long).to(device) for k,v in batch.items()}\n","        with torch.no_grad():        \n","            outputs = model(**batch)\n","            loss, logits = outputs[:2]\n","            logits = logits.detach().cpu().numpy()\n","            total_loss += loss.item()\n","            predict_content = logits.argmax(axis=-1).flatten().tolist()\n","            predictions_labels += predict_content\n","\n","    avg_epoch_val_loss = total_loss / len(val_dataloader)\n","    print('Validation loss:', avg_epoch_val_loss)\n","    \n","    torch.save(model.state_dict(), f'./ROBERTA_epoch_{epoch}_val_loss_{avg_epoch_val_loss}.pt')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.9 (default, Oct 26 2021, 07:25:53) \n[Clang 13.0.0 (clang-1300.0.29.30)]"},"vscode":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}}},"nbformat":4,"nbformat_minor":4}
